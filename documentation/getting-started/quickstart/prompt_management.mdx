---
title: "Quickstart"
description: "Create, deploy, and use your first prompt in minutes."
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>

<Accordion title="Use AI">
Add the [Docs MCP](/documentation/getting-started/ask-ai) to your AI coding tool to get help building with Respan. No API key needed.
```json
{
  "mcpServers": {
    "respan-docs": {
      "url": "https://docs.respan.ai/mcp"
    }
  }
}
```
</Accordion>


## What is prompt management?

Prompt management lets you create, version, and deploy prompt templates centrally — instead of hardcoding prompts in your application, reference them by ID.

<CodeGroup>
```python Without prompt management
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
            "role": "system",
            "content": "You are a helpful customer support agent for TechCorp."
        },
        {
            "role": "user",
            "content": f"Customer {customer_name} is asking about {issue_type}"
        }
    ]
)
```

```python With prompt management
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "placeholder"}],
    extra_body={
        "prompt": {
            "prompt_id": "042f5f",
            "variables": {
                "customer_name": "John",
                "issue_type": "billing"
            },
            "override": True
        }
    }
)
```
</CodeGroup>

---

## Prerequisites

Before you begin, make sure you have:

1. **Respan API key** — get one from the [API keys page](https://platform.respan.ai/platform/api/api-keys). See [API keys](/documentation/admin/respan_api_keys) for details.
2. **LLM provider key** — add your provider credentials (e.g. OpenAI) on the [Providers page](https://platform.respan.ai/platform/api/providers). See [LLM provider keys](/documentation/admin/llm_provider_keys) for details.

---

## Create your first prompt

<Steps>
<Step title="Create a new prompt">
Go to the [Prompts page](https://platform.respan.ai/platform/prompts) and click **Create new prompt**. Name your prompt and add a description.

<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/create-new-prompt.png" alt="Create new prompt" />
</Step>

<Step title="Configure the prompt">
In the **Editor** tab, set parameters like model, temperature, max tokens, and top P in the right sidebar.

<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/configure-prompt.png" alt="Configure prompt" />
</Step>

<Step title="Write content with variables">
Click **+ Add message** to add messages. Use `{{variable_name}}` for dynamic content — see [Variables](/documentation/features/prompt-management/manage-prompts#variables) for Jinja templates, JSON inputs, and more.

```
Please develop an optimized Python function to {{task_description}},
utilizing {{specific_library}}, include error handling, and write unit tests.
```

<Note>
Variable names must use underscores: `{{task_description}}` not `{{task description}}`.
</Note>

<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/prompt-variables.png" alt="Prompt with variables" />
</Step>

<Step title="Test and commit">
1. Add values for each variable in the **Variables** tab.
2. Click **Run** to test.
3. Click **Commit** and write a commit message to save this version.

<Warning>
**Avoid "Commit + deploy"** unless you want changes to go live immediately.
</Warning>

<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/get-started/prompt-commit.png" alt="Commit prompt" />
</Step>

<Step title="Deploy to production">
Go to the **Deployments** tab and click **Deploy**. See [Deployment & versioning](/documentation/features/prompt-management/manage-prompts#deployment--versioning) for version pinning, rollbacks, and overrides.

<Warning>
Deploying immediately affects production. All API calls using this prompt will use the new version right away.
</Warning>

<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/prompt/prompts-deploy.jpg" alt="Deploy prompt" />
</Frame>
</Step>
</Steps>

---

## Use your prompt in code

Find the **Prompt ID** in the Overview panel on the [Prompts page](https://platform.respan.ai/platform/prompts).

<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/prompt/prompt-id.png" alt="Find Prompt ID" />
</Frame>

Then call it from your application using **prompt schema v2 (recommended)**:

<Note>
OpenAI SDKs strip v2 fields like `schema_version` and `patch`. Prompt schema v2 requires raw HTTP requests.
</Note>

<CodeGroup>
```python Python
import requests

headers = {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_RESPAN_API_KEY',
}

data = {
    'prompt': {
        'prompt_id': 'YOUR_PROMPT_ID',
        'schema_version': 2,
        'variables': {
            'task_description': 'Square a number',
            'specific_library': 'math'
        }
    }
}

response = requests.post(
    'https://api.respan.ai/api/chat/completions',
    headers=headers,
    json=data
)
print(response.json())
```
```typescript TypeScript
fetch('https://api.respan.ai/api/chat/completions', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer YOUR_RESPAN_API_KEY'
    },
    body: JSON.stringify({
        prompt: {
            prompt_id: 'YOUR_PROMPT_ID',
            schema_version: 2,
            variables: {
                task_description: 'Square a number',
                specific_library: 'math'
            }
        }
    })
})
.then(response => response.json())
.then(data => console.log(data));
```
</CodeGroup>

You don't need `model` and `messages` — the prompt configuration is used automatically.

<Accordion title="Legacy prompt schema v1 (default)">
With v1, use `override: true` to let the prompt config win over request-body parameters. This is the default when `schema_version` is omitted.

<CodeGroup>
```python Python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "placeholder"}],
    extra_body={
        "prompt": {
            "prompt_id": "YOUR_PROMPT_ID",
            "variables": {
                "task_description": "Square a number",
                "specific_library": "math"
            },
            "override": True
        }
    }
)
```
```typescript TypeScript
const response = await client.chat.completions.create({
    messages: [{ role: "user", content: "placeholder" }],
    model: "gpt-4o-mini",
    // @ts-expect-error
    prompt: {
        prompt_id: "YOUR_PROMPT_ID",
        variables: {
            task_description: "Square a number",
            specific_library: "math"
        },
        override: true
    }
});
```
</CodeGroup>

See [Prompt merge modes (v1 vs v2)](/documentation/features/prompt-management/manage-prompts#prompt-merge-modes-v1-vs-v2) for full details.
</Accordion>

---

## Monitor your prompts

Filter logs by prompt name on the [Logs page](https://platform.respan.ai/platform/requests) to track usage, response times, and token consumption. See [Prompt logging](/documentation/features/prompt-management/manage-prompts#prompt-logging) for logging setup.

<Frame>
<img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/prompt/prompt-logs.png" alt="Monitor prompts" />
</Frame>

---

## Next steps

- [Variables](/documentation/features/prompt-management/manage-prompts#variables) — Jinja templates, conditionals, and JSON inputs
- [JSON schema](/documentation/features/prompt-management/manage-prompts#json-schema-structured-output) — structured output for consistent response formats
- [Prompt composition](/documentation/features/prompt-management/manage-prompts#prompt-composition) — reference prompts inside other prompts
- [Prompt merge modes (v1 vs v2)](/documentation/features/prompt-management/manage-prompts#prompt-merge-modes-v1-vs-v2) — control how prompt config and request params are merged
- [Deployment & versioning](/documentation/features/prompt-management/manage-prompts#deployment--versioning) — version pinning, rollbacks, and overrides
- [Streaming](/documentation/features/prompt-management/manage-prompts#streaming) — enable streaming for prompt responses
- [Playground](/documentation/features/prompt-management/manage-prompts#playground) — test and iterate on prompts interactively
