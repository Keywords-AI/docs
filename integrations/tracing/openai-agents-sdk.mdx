---
title: "OpenAI Agents"
description: "Trace OpenAI Agents SDK workflows, tool calls, and handoffs with Respan."
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>

## What is OpenAI Agents SDK?

The [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) is a lightweight framework for building multi-agent workflows with tools, handoffs, and guardrails. It provides a built-in tracing system that captures agent runs, LLM generations, tool calls, and agent-to-agent handoffs.

<Check>
Example project: [GitHub Link](https://github.com/respanai/respan-example-projects/tree/main/python/tracing/openai-agents-sdk)
</Check>

## Setup

<Steps>
<Step title="Install packages">

<CodeGroup>
```bash Python
pip install openai-agents respan-exporter-openai-agents
```
```bash JavaScript
npm install @openai/agents @respan/exporter-openai-agents
```
</CodeGroup>

</Step>

<Step title="Set environment variables">

```bash
export RESPAN_API_KEY="YOUR_RESPAN_API_KEY"
export OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
```

</Step>

<Step title="Initialize and run">

<CodeGroup>
```python Python
from agents import Agent, Runner, set_trace_processors
from respan_exporter_openai_agents import RespanTraceProcessor

# Set up Respan trace processor
respan_processor = RespanTraceProcessor()
set_trace_processors([respan_processor])

# Create and run agent
agent = Agent(
    name="Joke Agent",
    instructions="You are a helpful assistant that tells jokes.",
)

result = Runner.run_sync(agent, "Tell me a joke about AI")
print(result.final_output)
```
```typescript JavaScript
import { Agent, run, setTraceProcessors } from '@openai/agents';
import { RespanTraceProcessor } from '@respan/exporter-openai-agents';

setTraceProcessors([new RespanTraceProcessor({ apiKey: process.env.RESPAN_API_KEY! })]);

const agent = new Agent({
  name: 'Joke Agent',
  instructions: 'You are a helpful assistant that tells jokes.',
});

const result = await run(agent, 'Tell me a joke about AI');
console.log(result.finalOutput);
```
</CodeGroup>

</Step>

<Step title="View your trace">

Open the [Traces page](https://platform.respan.ai/platform/traces) to see your agent trace tree.

<Frame className="rounded-md">
<img width="100%" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/integrations/tracing/openai-agents/openai-agents-trace.png" alt="OpenAI Agents trace" />
</Frame>

</Step>
</Steps>

## Configuration

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `api_key` | `str` | `RESPAN_API_KEY` env var | Respan API key. |
| `endpoint` | `str \| None` | `None` | Custom ingest endpoint URL. |

See the OpenAI Agents Exporter SDK reference for [Python](/sdks/python/exporters/openai-agents) or [TypeScript](/sdks/typescript/exporters/openai-agents).

## Tool calls

Tool calls are automatically captured as spans with inputs, outputs, and timing.

<CodeGroup>
```python Python
from agents import Agent, Runner, set_trace_processors, function_tool
from respan_exporter_openai_agents import RespanTraceProcessor

set_trace_processors([RespanTraceProcessor()])

@function_tool
def get_weather(city: str) -> str:
    return f"The weather in {city} is sunny, 72°F"

agent = Agent(
    name="Weather Agent",
    instructions="Help users check the weather.",
    tools=[get_weather],
)

result = Runner.run_sync(agent, "What's the weather in San Francisco?")
print(result.final_output)
```
```typescript JavaScript
import { Agent, run, setTraceProcessors, tool } from '@openai/agents';
import { RespanTraceProcessor } from '@respan/exporter-openai-agents';
import { z } from 'zod';

setTraceProcessors([new RespanTraceProcessor({ apiKey: process.env.RESPAN_API_KEY! })]);

const getWeather = tool({
  name: 'get_weather',
  description: 'Get weather for a city',
  parameters: z.object({ city: z.string() }),
  execute: async ({ city }) => `The weather in ${city} is sunny, 72°F`,
});

const agent = new Agent({
  name: 'Weather Agent',
  instructions: 'Help users check the weather.',
  tools: [getWeather],
});

const result = await run(agent, "What's the weather in San Francisco?");
console.log(result.finalOutput);
```
</CodeGroup>

## Handoffs

Agent-to-agent handoffs are traced with full context.

```python
from agents import Agent, Runner, set_trace_processors
from respan_exporter_openai_agents import RespanTraceProcessor

set_trace_processors([RespanTraceProcessor()])

billing_agent = Agent(
    name="Billing Agent",
    instructions="Handle billing questions.",
)

support_agent = Agent(
    name="Support Agent",
    instructions="Route billing questions to the billing agent.",
    handoffs=[billing_agent],
)

result = Runner.run_sync(support_agent, "I have a billing question")
print(result.final_output)
```

## Agents as tools

Instead of handoffs (where the new agent takes over), you can use agents as tools — the tool agent runs independently and returns its result to the caller:

```python
from agents import Agent, Runner, set_trace_processors, trace
from respan_exporter_openai_agents import RespanTraceProcessor

set_trace_processors([RespanTraceProcessor()])

spanish_agent = Agent(
    name="spanish_agent",
    instructions="You translate the user's message to Spanish",
)

french_agent = Agent(
    name="french_agent",
    instructions="You translate the user's message to French",
)

orchestrator = Agent(
    name="orchestrator",
    instructions="You are a translation agent. Use the provided tools to translate.",
    tools=[
        spanish_agent.as_tool(
            tool_name="translate_to_spanish",
            tool_description="Translate to Spanish",
        ),
        french_agent.as_tool(
            tool_name="translate_to_french",
            tool_description="Translate to French",
        ),
    ],
)

with trace("Translation orchestrator"):
    result = Runner.run_sync(orchestrator, "Translate 'hello' to Spanish and French")
    print(result.final_output)
```

## Guardrails

Run input guardrails in parallel with the agent to quickly reject invalid inputs:

```python
from agents import (
    Agent, Runner, set_trace_processors,
    input_guardrail, GuardrailFunctionOutput,
    InputGuardrailTripwireTriggered, RunContextWrapper,
)
from pydantic import BaseModel
from respan_exporter_openai_agents import RespanTraceProcessor

set_trace_processors([RespanTraceProcessor()])

class MathHomeworkOutput(BaseModel):
    is_math_homework: bool
    reasoning: str

guardrail_agent = Agent(
    name="Guardrail check",
    instructions="Check if the user is asking you to do their math homework.",
    output_type=MathHomeworkOutput,
)

@input_guardrail
async def math_guardrail(context, agent, input):
    result = await Runner.run(guardrail_agent, input, context=context.context)
    output = result.final_output_as(MathHomeworkOutput)
    return GuardrailFunctionOutput(
        output_info=output,
        tripwire_triggered=output.is_math_homework,
    )

agent = Agent(
    name="Support Agent",
    instructions="You are a customer support agent.",
    input_guardrails=[math_guardrail],
)

try:
    result = await Runner.run(agent, "Solve for x: 2x + 5 = 11")
except InputGuardrailTripwireTriggered:
    print("Guardrail triggered — input rejected")
```

## Dynamic system prompts

Use a function for `instructions` to customize prompts based on runtime context:

```python
from agents import Agent, Runner, RunContextWrapper, set_trace_processors
from respan_exporter_openai_agents import RespanTraceProcessor

set_trace_processors([RespanTraceProcessor()])

class CustomContext:
    def __init__(self, style: str):
        self.style = style

def custom_instructions(
    run_context: RunContextWrapper[CustomContext], agent: Agent
) -> str:
    if run_context.context.style == "haiku":
        return "Only respond in haikus."
    elif run_context.context.style == "pirate":
        return "Respond as a pirate."
    return "Respond normally."

agent = Agent(name="Chat agent", instructions=custom_instructions)

result = await Runner.run(
    agent, "Tell me a joke.", context=CustomContext(style="pirate")
)
print(result.final_output)
```
