---
title: "Langfuse"
description: "Redirect Langfuse traces to Respan with OTEL instrumentation."
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>

<Accordion title="Use AI">
Add the [Docs MCP](/documentation/getting-started/ask-ai) to your AI coding tool to get help building with Respan. No API key needed.
```json
{
  "mcpServers": {
    "respan-docs": {
      "url": "https://docs.respan.ai/mcp"
    }
  }
}
```
</Accordion>

## What is Langfuse?

[Langfuse](https://langfuse.com/) is an open-source LLM observability platform. The Respan instrumentor patches Langfuse's OTLP exporter to redirect traces to Respan — your existing `@observe` decorators and `langfuse.trace()` calls continue to work unchanged.

<Check>
Example project: [GitHub Link](https://github.com/respanai/respan-example-projects/tree/main/python/tracing/langfuse)
</Check>

## Setup

<Steps>
<Step title="Install packages">

```bash
pip install langfuse respan-instrumentation-langfuse
```

</Step>

<Step title="Set environment variables">

```bash
export RESPAN_API_KEY="YOUR_RESPAN_API_KEY"
export LANGFUSE_PUBLIC_KEY="YOUR_LANGFUSE_PUBLIC_KEY"
export LANGFUSE_SECRET_KEY="YOUR_LANGFUSE_SECRET_KEY"
```

</Step>

<Step title="Instrument before importing Langfuse">

<Warning>
`LangfuseInstrumentor().instrument()` must be called **before** importing `langfuse`. The instrumentor patches the OTLP exporter at import time.
</Warning>

```python
import os
from respan_instrumentation_langfuse import LangfuseInstrumentor

# Instrument BEFORE importing langfuse
LangfuseInstrumentor().instrument()

# Now import and use langfuse normally
from langfuse.decorators import observe
from openai import OpenAI

client = OpenAI()

@observe()
def generate_joke():
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": "Tell me a joke about AI"}],
    )
    return response.choices[0].message.content

@observe()
def joke_pipeline():
    joke = generate_joke()
    return joke

result = joke_pipeline()
print(result)
```

</Step>

<Step title="View your trace">

Open the [Traces page](https://platform.respan.ai/platform/traces) to see your Langfuse traces in Respan.

<Frame className="rounded-md">
<img width="100%" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/integrations/tracing/langfuse/langfuse-trace.png" alt="Langfuse trace in Respan" />
</Frame>

</Step>
</Steps>

## Configuration

See the [Langfuse Instrumentor SDK reference](/sdks/python/exporters/langfuse) for the full API.

